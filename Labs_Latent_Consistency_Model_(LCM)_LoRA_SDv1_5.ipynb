{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Ref: https://huggingface.co/latent-consistency/lcm-lora-sdv1-5"
      ],
      "metadata": {
        "id": "KCgNYDYfao9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APGnxygLiuh3"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade diffusers transformers accelerate peft"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Text to image"
      ],
      "metadata": {
        "id": "lY0_QrL1uXKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code run pada GPU"
      ],
      "metadata": {
        "id": "IPWBZWVTKi1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import torch\n",
        "from diffusers import LCMScheduler, AutoPipelineForText2Image\n",
        "\n",
        "model_id = \"Lykon/dreamshaper-7\"\n",
        "adapter_id = \"latent-consistency/lcm-lora-sdv1-5\"\n",
        "\n",
        "# if Run on GPU\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "# pipe.to(\"gpu\")\n",
        "pipe.to(device=\"cuda\", dtype=torch.float16)\n",
        "\n",
        "# if run on CPU\n",
        "# pipe = AutoPipelineForText2Image.from_pretrained(model_id, variant=\"fp16\")\n",
        "# pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# load and fuse lcm lora\n",
        "pipe.load_lora_weights(adapter_id)\n",
        "pipe.fuse_lora()\n",
        "\n",
        "user_prompt = \"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"\n",
        "\n",
        "# disable guidance_scale by passing 0\n",
        "# image = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0).images[0]\n",
        "\n",
        "# Menjalankan inferensi dengan prompt yang dimasukkan pengguna\n",
        "results = pipe(\n",
        "    prompt=user_prompt,\n",
        "    num_inference_steps=4,\n",
        "    guidance_scale=0.5\n",
        "    # nsfw=False\n",
        ")\n",
        "\n",
        "# Menampilkan gambar di Google Colab\n",
        "display(results.images[0])"
      ],
      "metadata": {
        "id": "_NssVyO1KpSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code run pada CPU"
      ],
      "metadata": {
        "id": "k2JhfOd1Kdsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import torch\n",
        "from diffusers import LCMScheduler, AutoPipelineForText2Image\n",
        "\n",
        "model_id = \"Lykon/dreamshaper-7\"\n",
        "adapter_id = \"latent-consistency/lcm-lora-sdv1-5\"\n",
        "\n",
        "# if Run on GPU\n",
        "# pipe = AutoPipelineForText2Image.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\")\n",
        "# pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "# pipe.to(\"gpu\")\n",
        "\n",
        "# if run on CPU\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(model_id, variant=\"fp16\")\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# load and fuse lcm lora\n",
        "pipe.load_lora_weights(adapter_id)\n",
        "pipe.fuse_lora()\n",
        "\n",
        "user_prompt =  \"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"\n",
        "\n",
        "# disable guidance_scale by passing 0\n",
        "# image = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0).images[0]\n",
        "\n",
        "# Menjalankan inferensi dengan prompt yang dimasukkan pengguna\n",
        "results = pipe(\n",
        "    prompt=user_prompt,\n",
        "    num_inference_steps=4,\n",
        "    guidance_scale=0\n",
        "    # nsfw=False\n",
        ")\n",
        "\n",
        "# Menampilkan gambar di Google Colab\n",
        "display(results.images[0])"
      ],
      "metadata": {
        "id": "oxMpigqMtv5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.a Text to image - test guidence_scale 0 - 1"
      ],
      "metadata": {
        "id": "o84OyEXruVvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import LCMScheduler, AutoPipelineForText2Image\n",
        "from IPython.display import display\n",
        "\n",
        "model_id = \"Lykon/dreamshaper-7\"\n",
        "adapter_id = \"latent-consistency/lcm-lora-sdv1-5\"\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# load and fuse lcm lora\n",
        "pipe.load_lora_weights(adapter_id)\n",
        "pipe.fuse_lora()\n",
        "\n",
        "user_prompt = \"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\" #\"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"\n",
        "\n",
        "\"\"\"\n",
        "# Menjalankan serangkaian pengujian dengan berbagai nilai guidance_scale\n",
        "num_tests = 11  # Jumlah pengujian, termasuk guidance_scale=0 hingga 10\n",
        "images = []\n",
        "\n",
        "for guidance_scale_value in range(num_tests):\n",
        "    # Menjalankan inferensi dengan nilai guidance_scale yang berbeda\n",
        "    results = pipe(\n",
        "        prompt=user_prompt,\n",
        "        num_inference_steps=8,\n",
        "        guidance_scale=guidance_scale_value\n",
        "        # nsfw=False\n",
        "    )\n",
        "\n",
        "    # Menyimpan gambar pada list images\n",
        "    images.append(results.images[0])\n",
        "\"\"\"\n",
        "\n",
        "# Menjalankan serangkaian pengujian dengan berbagai nilai guidance_scale\n",
        "guidance_scale_values = [i / 10.0 for i in range(11)]  # [0.0, 0.1, 0.2, ..., 1.0]\n",
        "images = []\n",
        "\n",
        "for guidance_scale_value in guidance_scale_values:\n",
        "    # Menjalankan inferensi dengan nilai guidance_scale yang berbeda\n",
        "    results = pipe(\n",
        "        prompt=user_prompt,\n",
        "        num_inference_steps=8,\n",
        "        guidance_scale=guidance_scale_value\n",
        "        # nsfw=False\n",
        "    )\n",
        "\n",
        "    # Menyimpan gambar pada list images\n",
        "    images.append(results.images[0])\n",
        "\n",
        "# Menampilkan semua gambar\n",
        "for i, image in enumerate(images):\n",
        "    display(image)"
      ],
      "metadata": {
        "id": "mevx8TqNt1jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show all images"
      ],
      "metadata": {
        "id": "qLpMgzKzZsKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Menampilkan gambar dengan mengatur ukuran subplot dinamis\n",
        "num_rows = (len(images) - 1) // 4 + 1\n",
        "fig, axs = plt.subplots(num_rows, 4, figsize=(20, 5 * num_rows))\n",
        "\n",
        "for i in range(num_rows):\n",
        "    for j in range(4):\n",
        "        index = i * 4 + j\n",
        "        if index < len(images):\n",
        "            axs[i, j].imshow(images[index])\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(f'Guidance Scale = {guidance_scale_values[index]:.1f}')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7sSh5qiNvKr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Image2Image GPU"
      ],
      "metadata": {
        "id": "mAlsBY4Jzxu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import AutoPipelineForImage2Image, LCMScheduler\n",
        "from diffusers.utils import make_image_grid, load_image\n",
        "\n",
        "pipe = AutoPipelineForImage2Image.from_pretrained(\n",
        "    \"Lykon/dreamshaper-7\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "# set scheduler\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# load LCM-LoRA\n",
        "pipe.load_lora_weights(\"latent-consistency/lcm-lora-sdv1-5\")\n",
        "pipe.fuse_lora()\n",
        "\n",
        "# prepare image\n",
        "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png\"\n",
        "init_image = load_image(url)\n",
        "prompt = \"Original face, self-portrait oil painting, a handsome cyborg with golden hair, 8k\"\n",
        "\n",
        "# pass prompt and image to pipeline\n",
        "generator = torch.manual_seed(0)\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    image=init_image,\n",
        "    num_inference_steps=8,\n",
        "    guidance_scale=0.5,\n",
        "    strength=0.6,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "make_image_grid([init_image, image], rows=1, cols=2)\n"
      ],
      "metadata": {
        "id": "YEUNLK8nz15A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Inpainting GPU"
      ],
      "metadata": {
        "id": "gPtckT5daO1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import AutoPipelineForInpainting, LCMScheduler\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "\n",
        "pipe = AutoPipelineForInpainting.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-inpainting\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "# set scheduler\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# load LCM-LoRA\n",
        "pipe.load_lora_weights(\"latent-consistency/lcm-lora-sdv1-5\")\n",
        "pipe.fuse_lora()\n",
        "\n",
        "# load base and mask image\n",
        "init_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\n",
        "mask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n",
        "\n",
        "# generator = torch.Generator(\"cuda\").manual_seed(92)\n",
        "prompt = \"concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k\"\n",
        "generator = torch.manual_seed(0)\n",
        "image = pipe(\n",
        "    prompt=prompt,\n",
        "    image=init_image,\n",
        "    mask_image=mask_image,\n",
        "    generator=generator,\n",
        "    num_inference_steps=4,\n",
        "    guidance_scale=4,\n",
        ").images[0]\n",
        "make_image_grid([init_image, mask_image, image], rows=1, cols=3)\n"
      ],
      "metadata": {
        "id": "nSp7__yGaJAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. ControlNet GPU"
      ],
      "metadata": {
        "id": "lbCcn9mlaXUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, LCMScheduler\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "image = load_image(\n",
        "    \"https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png\"\n",
        ").resize((512, 512))\n",
        "\n",
        "image = np.array(image)\n",
        "\n",
        "low_threshold = 100\n",
        "high_threshold = 200\n",
        "\n",
        "image = cv2.Canny(image, low_threshold, high_threshold)\n",
        "image = image[:, :, None]\n",
        "image = np.concatenate([image, image, image], axis=2)\n",
        "canny_image = Image.fromarray(image)\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# set scheduler\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# load LCM-LoRA\n",
        "pipe.load_lora_weights(\"latent-consistency/lcm-lora-sdv1-5\")\n",
        "\n",
        "generator = torch.manual_seed(0)\n",
        "image = pipe(\n",
        "    \"the mona lisa\",\n",
        "    image=canny_image,\n",
        "    num_inference_steps=4,\n",
        "    guidance_scale=1.5,\n",
        "    controlnet_conditioning_scale=0.8,\n",
        "    cross_attention_kwargs={\"scale\": 1},\n",
        "    generator=generator,\n",
        ").images[0]\n",
        "make_image_grid([canny_image, image], rows=1, cols=2)\n"
      ],
      "metadata": {
        "id": "SsRuUYKsaRgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}