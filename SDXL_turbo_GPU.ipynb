{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Link referensi\n",
        "1. https://huggingface.co/stabilityai\n",
        "2. https://huggingface.co/stabilityai/sdxl-turbo\n",
        "3. https://github.com/Stability-AI/generative-models.git\n"
      ],
      "metadata": {
        "id": "y-P6BpXv-hTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade diffusers transformers accelerate peft"
      ],
      "metadata": {
        "id": "xJ0bWdUn-dvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. SDXL turbo - Text2Image - GPU"
      ],
      "metadata": {
        "id": "HrgFGNleDWiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"\n",
        "\n",
        "image = pipe(\n",
        "    prompt=prompt,\n",
        "    num_inference_steps=1,\n",
        "    guidance_scale=0.0).images[0]\n",
        "\n",
        "display(image)"
      ],
      "metadata": {
        "id": "_iN72tu8DT_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. SDXL turbo - Text2Image - GPU"
      ],
      "metadata": {
        "id": "ID0Fhym59417"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForImage2Image\n",
        "from diffusers.utils import load_image\n",
        "import torch\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "# Load pre-trained model\n",
        "pipe = AutoPipelineForImage2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# URL of the original image\n",
        "image_url = \"https://hips.hearstapps.com/hmg-prod/images/gettyimages-1229892983-square.jpg\" # \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\"\n",
        "\n",
        "# Define prompt for generation\n",
        "prompt = \"Handsome, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k\"\n",
        "\n",
        "# Load original image and resize\n",
        "original_image = load_image(image_url).resize((512, 512))\n",
        "\n",
        "# Generate image using the model\n",
        "generated_image = pipe(prompt, image=original_image, num_inference_steps=2, strength=0.5, guidance_scale=0.0).images[0]\n",
        "\n",
        "# Create a new blank image with the desired size for display\n",
        "display_image = Image.new(\"RGB\", (1024, 512))\n",
        "\n",
        "# Paste original image on the left side\n",
        "display_image.paste(original_image, (0, 0))\n",
        "\n",
        "# Paste generated image on the right side\n",
        "display_image.paste(generated_image, (512, 0))\n",
        "\n",
        "# Display the combined image\n",
        "display(display_image)\n"
      ],
      "metadata": {
        "id": "C_CKbwuC-Cp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_z_y40AC0wh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}